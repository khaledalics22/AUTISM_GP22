{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio as io\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage.io as io\n",
    "import math\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import gaussian\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from skimage.util import invert\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin\n",
    "from scipy.ndimage.morphology import binary_hit_or_miss\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from operator import eq\n",
    "from sklearn import preprocessing\n",
    "from skimage import color\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio as io\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage.io as io\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import color\n",
    "from operator import eq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linehorizontalHaarfeatures(integral_image,window_height,window_width):\n",
    "    linehorizontalHaarfeatures=[]\n",
    "    window_width_third=int(window_width/3)\n",
    "    i=0\n",
    "    j=0\n",
    "    while(i+window_height<integral_image.shape[0]):\n",
    "        while(j+window_width<integral_image.shape[1]):\n",
    "            white_Pixels_inHaar = integral_image[i+window_height][j+window_width_third]-integral_image[i+window_height][j]-integral_image[i][j+window_width_third]+integral_image[i][j]\n",
    "            black_Pixels_inHaar = integral_image[i+window_height][j+window_width_third*2]-integral_image[i+window_height][j+window_width_third]-integral_image[i][j+window_width_third*2]+integral_image[i][j+window_width_third]\n",
    "            white2_Pixels_inHaar = integral_image[i+window_height][j+window_width]-integral_image[i+window_height][j+window_width_third*2]-integral_image[i][j+window_width]+integral_image[i][j+window_width_third*2]\n",
    "            delta=(white_Pixels_inHaar-black_Pixels_inHaar+white2_Pixels_inHaar)/(window_height*window_width_third)\n",
    "            linehorizontalHaarfeatures.append(delta)\n",
    "            j=j+1\n",
    "        i=i+1  \n",
    "    return linehorizontalHaarfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integralimage (img): \n",
    "    height,width=img.shape\n",
    "    integral_image= np.zeros((height+1,width+1))#to add maargin 0 on top and on right\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            integral_image[i][j]=img[i][j]+integral_image[i-1][j]+integral_image[i][j-1]-integral_image[i-1][j-1]#because we add the right top pixcel twice\n",
    "    return integral_image                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extarct Mouth using Haar Feature\n",
    "def get_mouth(img,w=30,h=3):\n",
    "    i=get_integralimage (img)\n",
    "    integral_image=np.delete(i, img.shape[0],0)\n",
    "    img=integral_image=np.delete(i,img.shape[1],1)    #to remove the margin\n",
    "    im1=get_linehorizontalHaarfeatures(img,w,h)\n",
    "    im1=np.array(im1)\n",
    "    im1 = im1.reshape(5,9)\n",
    "    return im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img  = io.imread('angry.png')\n",
    "# neg_arr=np.zeros((img.shape[0],img.shape[1]), np.uint8)[0]\n",
    "# # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# i=get_integralimage (img)\n",
    "# integral_image=np.delete(i, img.shape[0],0)\n",
    "# integral_image=np.delete(i,img.shape[1],1)    #to remove the margin\n",
    "# # print(integral_image)\n",
    "# im1=get_linehorizontalHaarfeatures(integral_image,40,3)\n",
    "# im1=np.array(im1)\n",
    "# print(np.array(im1).shape)\n",
    "# im1 = im1.reshape(5,9)\n",
    "# # neg_arr[:]=im1\n",
    "# plt.imshow(im1,cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "# if face.empty():\n",
    "#     raise IOError('Unable to load the face cascade classifier xml file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "# if mouth_cascade.empty():\n",
    "#     raise IOError('Unable to load the mouth cascade classifier xml file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    img=imgmouth=get_mouth(img)\n",
    "    if(np.array(imgmouth).any()==None):\n",
    "        print(\"None\")\n",
    "    img = img.astype(int)\n",
    "    target_img_size = (78, 78)\n",
    "    img = cv2.resize(img.astype('uint8'), target_img_size)\n",
    "    #64--.i.e 2 block\n",
    "    win_size = (64, 64)\n",
    "    cell_size = (8, 8)\n",
    "    block_size_in_cells = (2, 2)\n",
    "\n",
    "    block_size = (block_size_in_cells[1] * cell_size[1],\n",
    "                  block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 15  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size,\n",
    "                            block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccessing(img):\n",
    "    gray=color.rgb2gray(img)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_mouth(img):\n",
    "#     pre_img=preproccessing(img)\n",
    "#     original_image=pre_img\n",
    "#     pre_img = np.array(pre_img, dtype='uint8')\n",
    "#     mouth_rects = mouth_cascade.detectMultiScale(pre_img,1.2, 10)\n",
    "#     for (x,y,w,h) in mouth_rects:\n",
    "#         #print(x,y,w,h)\n",
    "#         y = int(y - 0.15*h)\n",
    "#         #cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,255),1)\n",
    "#         cropped_contour= original_image[y:y+h, x:x+w]\n",
    "#         image_name= \"output_shape_number.jpg\"\n",
    "#         cv2.imwrite(image_name, cropped_contour)\n",
    "        \n",
    "#         readimage= cv2.imread(image_name) \n",
    "#         return readimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_dataset =r'D:\\Download\\jaffedbase'\n",
    "path_to_dataset =r'E:\\emotion\\archive\\ck\\CK+48'\n",
    "# path_to_dataset =r'E:\\datasetemotion\\val\\val'\n",
    "img_filenames = os.listdir(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "img_filenames = os.listdir(path_to_dataset)\n",
    "print(img_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(feature_set='hog'):\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "            label = fn.split('.')[0]\n",
    "            path = os.path.join(path_to_dataset, fn)\n",
    "            subpath=os.listdir(path)\n",
    "            for k, d in enumerate(subpath):             \n",
    "                imgpath = os.path.join(path, d)\n",
    "                img = io.imread(imgpath)\n",
    "                img = cv2.resize(img,(48,48), interpolation = cv2.INTER_AREA)\n",
    "                img=color.rgb2gray(img)\n",
    "                if(np.array(extract_features(img)).any()!=None):\n",
    "                    labels.append(label)\n",
    "                    features.append(extract_features(img))\n",
    "                if k > 0 and k % 100 == 0:\n",
    "                    print(\"[INFO] processed {}/{}\".format(k, len(subpath)))\n",
    "    return features, labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    return extract_hog_features(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features,labels,precentage):\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed)\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classifier(kcount,train_features, train_labels):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=kcount)\n",
    "    classifier.fit(list(train_features),list(train_labels) )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_features, test_features):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "    train_features = scaler.transform(train_features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(test_features, test_labels,classifier):\n",
    "        accuracy = classifier.score(test_features, test_labels)        \n",
    "        print('accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] processed 100/135\n",
      "[INFO] processed 100/177\n",
      "[INFO] processed 100/207\n",
      "[INFO] processed 200/207\n",
      "[INFO] processed 100/249\n",
      "[INFO] processed 200/249\n",
      "Finished loading dataset.\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset. This will take time ...')\n",
    "features, labels = load_dataset(feature_set='hog')\n",
    "\n",
    "print('Finished loading dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, labels1 =features, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 11760)\n",
      "(981,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(features1).shape)\n",
    "print(np.array(labels1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels=split_data(np.array(features1),np.array(labels1),0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 88.3248730964467\n",
      "train 99.87244897959184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "le = preprocessing.LabelEncoder()\n",
    "random_seed = 0  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "sigma=0.0008\n",
    "c=64\n",
    "reg=100\n",
    "err=1e-4\n",
    "#Get Kernel Function\n",
    "def kernel(X, Y=None,g=None):\n",
    "    k=rbf_kernel(X, Y, gamma=g)\n",
    "    return k\n",
    "#Get Output Weight \"Fitting Classifier\"\n",
    "def KELM_Beta(sigma,c,x,y):\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    emotion = len(np.unique(y))\n",
    "    One_Hot_Encoding=np.zeros((emotion,emotion), np.uint8)\n",
    "    for em in range (emotion):\n",
    "        One_Hot_Encoding[em][em]=1\n",
    "    T = One_Hot_Encoding[y, :]    \n",
    "    N,d=x.shape\n",
    "    Omega=kernel(x,None,sigma)\n",
    "    I=np.eye(N)\n",
    "    Beta = np.linalg.inv((I /c) + Omega).dot(T)    \n",
    "    return Beta,One_Hot_Encoding\n",
    "#Get Predicted Labels \"Predication\"\n",
    "def KELM_Output(sigma,x,x_test,Beta,One_Hot_Encoding):\n",
    "    hx=kernel(x_test,x,sigma)\n",
    "    fx= hx.dot(Beta)\n",
    "    p=np.argmax(fx,axis=1)\n",
    "    return p\n",
    "def acc(y_pred,test_labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    yt = le.fit_transform(y_pred)    \n",
    "    rt = le.fit_transform(test_labels)\n",
    "    eqw = sum(map(eq, list(rt), list(y_pred)))\n",
    "    size=len(rt)\n",
    "    acc=(eqw/size)*100\n",
    "    return acc\n",
    "Beta,One_Hot_Encoding=KELM_Beta(sigma,c,np.array(train_features),np.array(train_labels))\n",
    "p1=KELM_Output(sigma,np.array(train_features),np.array(test_features),Beta,One_Hot_Encoding)\n",
    "print(\"test\",acc(p1,test_labels))\n",
    "\n",
    "p2=KELM_Output(sigma,np.array(train_features),np.array(train_features),Beta,One_Hot_Encoding)\n",
    "print(\"train\",acc(p2,train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 11760)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_features)\n",
    "print(np.array(train_features).shape)\n",
    "print(np.array(train_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=KNN_classifier(3,train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_pred,test_labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    yt = le.fit_transform(y_pred)\n",
    "    rt = le.fit_transform(test_labels)\n",
    "    eqw = sum(map(eq, list(rt), list(yt)))\n",
    "    size=len(rt)\n",
    "    acc=(eqw/size)*100\n",
    "    print(acc)\n",
    "    print(yt)\n",
    "    print(rt)\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 72.08121827411168 %\n",
      "Train accuracy: 95.53571428571429 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(test_features, test_labels)\n",
    "print('Test accuracy:', accuracy*100, '%')\n",
    "accuracy = classifier.score(train_features, train_labels)\n",
    "print('Train accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7208121827411168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.85      0.74        20\n",
      "    contempt       0.44      0.67      0.53         6\n",
      "     disgust       0.71      0.66      0.68        41\n",
      "        fear       0.80      0.80      0.80        15\n",
      "       happy       0.70      0.85      0.77        39\n",
      "     sadness       0.67      0.55      0.60        22\n",
      "    surprise       0.84      0.69      0.76        54\n",
      "\n",
      "    accuracy                           0.72       197\n",
      "   macro avg       0.69      0.72      0.70       197\n",
      "weighted avg       0.73      0.72      0.72       197\n",
      "\n",
      "[[17  0  1  0  1  1  0]\n",
      " [ 0  4  0  0  2  0  0]\n",
      " [ 6  0 27  0  7  0  1]\n",
      " [ 0  0  0 12  0  1  2]\n",
      " [ 1  0  2  0 33  1  2]\n",
      " [ 0  4  4  0  0 12  2]\n",
      " [ 2  1  4  3  4  3 37]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, y_pred))\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(classifier, 'DellKNN2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18610714 0.21370839 0.15028238 ... 0.21837309 0.09984857 0.10134899]\n"
     ]
    }
   ],
   "source": [
    "# img  = io.imread('KA.AN2.40.tiff')\n",
    "img  = io.imread('MK.HA1.116.tiff')\n",
    "# img  = io.imread('UY.DI2.150.tiff')\n",
    "\n",
    "\n",
    "\n",
    "f=extract_features(img)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy']\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict([f] )\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 95.28061224489795\n",
      "test score 80.20304568527918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# k in ['rbf','sigmoid']\\\n",
    "# gamma in ['scale','auto']\n",
    "\n",
    "k='sigmoid'\n",
    "gamma = 'auto'\n",
    "c=400\n",
    "clf = SVC(C=c,kernel=k,gamma=gamma)\n",
    "clf.fit(train_features, train_labels)\n",
    "print ('train score', clf.score(train_features, train_labels)*100 )\n",
    "y=clf.predict(test_features)\n",
    "print ('test score', clf.score(test_features,test_labels)*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00         0\n",
      "    contempt       1.00      0.33      0.50         3\n",
      "     disgust       1.00      1.00      1.00         7\n",
      "        fear       1.00      1.00      1.00         1\n",
      "       happy       0.97      1.00      0.99        36\n",
      "    surprise       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.83      0.72      0.75        48\n",
      "weighted avg       0.98      0.96      0.96        48\n",
      "\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 1  1  0  0  1  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 0  0  0  0 36  0]\n",
      " [ 0  0  0  0  0  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, y))\n",
    "print(classification_report(test_labels, y))\n",
    "print(confusion_matrix(test_labels, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05678637 0.03077303 0.04064067 ... 0.09820569 0.14047983 0.19829692]\n"
     ]
    }
   ],
   "source": [
    "# img  = io.imread('KA.AN2.40.tiff')\n",
    "img  = io.imread('UY.DI2.150.tiff')\n",
    "# img  = io.imread('KL.SU1.164.tiff')\n",
    "# img  = io.imread('S010_004_00000017.png')\n",
    "# img  = io.imread('MK.HA1.116.tiff')\n",
    "f=extract_features(img)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy']\n"
     ]
    }
   ],
   "source": [
    "y_predsvm=clf.predict([f])\n",
    "print(y_predsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DellSVM.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# joblib.dump(clf, 'DellSVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
